{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## David Kartchner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:\n",
    "\n",
    "** Part 1:  Separate seed data into train and test sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seeds = np.loadtxt(\"seeds_dataset.txt\")\n",
    "num_rows = seeds.shape[0]\n",
    "num_cols = seeds.shape[1]\n",
    "test_rows = np.random.choice(num_rows, size=40, replace=False)\n",
    "test_data = seeds[test_rows]\n",
    "train_mask = np.ones(num_rows, dtype=bool)\n",
    "train_mask[test_rows] = 0\n",
    "train_data = seeds[train_mask]\n",
    "row_labels = ['Area', 'Perimeter', 'Compactness', 'Length', 'Width', 'Asymmetry Coefficient', 'Groove Length', 'Species']\n",
    "\n",
    "#Make datasets into Pandas data frames\n",
    "train = pd.DataFrame(train_data, index=list(range(train_data.shape[0])), columns=row_labels)\n",
    "train['Species'] = train['Species'].astype(\"category\")\n",
    "train['Species'].cat.categories = ['Kama', 'Rosa', 'Canadian']\n",
    "test = pd.DataFrame(test_data, index=list(range(test_data.shape[0])), columns=row_labels)\n",
    "test['Species'] = test['Species'].astype(\"category\")\n",
    "test['Species'].cat.categories = ['Kama', 'Rosa', 'Canadian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Calculate mean and variance of each feature for each type of wheat using training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      "               Area  Perimeter  Compactness    Length     Width  \\\n",
      "Species                                                           \n",
      "Kama      14.214407  14.241525     0.879208  5.491051  3.228237   \n",
      "Rosa      18.532586  16.215690     0.884469  6.175690  3.700190   \n",
      "Canadian  11.810943  13.217547     0.848853  5.217472  2.844189   \n",
      "\n",
      "          Asymmetry Coefficient  Groove Length  \n",
      "Species                                         \n",
      "Kama                   2.650054       5.069949  \n",
      "Rosa                   3.650603       6.036741  \n",
      "Canadian               4.673755       5.108000  \n",
      "\n",
      "\n",
      "Variances:\n",
      "              Area  Perimeter  Compactness    Length     Width  \\\n",
      "Species                                                          \n",
      "Kama      1.457263   0.335827     0.000266  0.055029  0.031026   \n",
      "Rosa      1.845360   0.332053     0.000234  0.065830  0.033152   \n",
      "Canadian  0.504759   0.117603     0.000449  0.021173  0.021446   \n",
      "\n",
      "          Asymmetry Coefficient  Groove Length  \n",
      "Species                                         \n",
      "Kama                   1.330942       0.069931  \n",
      "Rosa                   1.483425       0.061904  \n",
      "Canadian               1.776107       0.027914  \n"
     ]
    }
   ],
   "source": [
    "grouped_train = train.groupby(\"Species\")\n",
    "means = grouped_train.mean()\n",
    "variances = grouped_train.var()\n",
    "\n",
    "kama_means = np.mean(train_data[np.where(train_data[:,-1]==1)], axis=0)[:-1]\n",
    "rosa_means = np.mean(train_data[np.where(train_data[:,-1]==2)], axis=0)[:-1]\n",
    "canadian_means = np.mean(train_data[np.where(train_data[:,-1]==3)], axis=0)[:-1]\n",
    "\n",
    "kama_vars = np.var(train_data[np.where(train_data[:,-1]==1)], axis=0)[:-1]\n",
    "rosa_vars = np.var(train_data[np.where(train_data[:,-1]==2)], axis=0)[:-1]\n",
    "canadian_vars = np.var(train_data[np.where(train_data[:,-1]==3)], axis=0)[:-1]\n",
    "\n",
    "print \"Means:\"\n",
    "print means\n",
    "print \"\\n\\nVariances:\"\n",
    "print variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3:  Predict labels using uniform prior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kama_probs = np.sum(-(test_data[:,:-1] - kama_means)**2/(2*kama_vars), axis=1) -.5*np.sum(np.log(2*np.pi*kama_vars)) + np.log(np.sum(train_data[:,-1]==1)/train_data.shape[0])\n",
    "rosa_probs = np.sum(-(test_data[:,:-1] - rosa_means)**2/(2*rosa_vars), axis=1) -.5*np.sum(np.log(2*np.pi*rosa_vars)) + np.log(np.sum(train_data[:,-1]==2)/train_data.shape[0])\n",
    "canadian_probs = np.sum(-(test_data[:,:-1] - canadian_means)**2/(2*canadian_vars), axis=1) -.5*np.sum(np.log(2*np.pi*canadian_vars)) + np.log(np.sum(train_data[:,-1]==3)/train_data.shape[0])\n",
    "likelihoods = np.array([kama_probs, rosa_probs, canadian_probs])\n",
    "predicted_vals = np.argmax(likelihoods, axis=0)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4: Show percent correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct:  0.875\n"
     ]
    }
   ],
   "source": [
    "num_misclassified = len(np.where((test_data[:,-1]-predicted_vals)!=0)[0])\n",
    "test_size = test_data.shape[0]\n",
    "percent_correct = (test_size-num_misclassified)/test_size\n",
    "print \"Percent Correct: \", percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(train_data[:,:-1], train_data[:,-1])\n",
    "pred_labels = nb_classifier.predict(test_data[:, :-1])\n",
    "print (test_data.shape[0] - sum(pred_labels != test_data[:,-1]))/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "\n",
    "**Create a Naive Bayes Classifier for spam recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naiveBayes(object):\n",
    "    \"\"\"\n",
    "    Perfoms naive bayes classification for word-count document features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print \"You've been initialized!\"\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            Y:  Nx1 array of labels for corresponding to each row of X.  Labels should be nonnegative integers.\n",
    "            X:  NxK array of feature counts, where each entry is an integer.  Each row of X corresponds to an entry of Y.\n",
    "        \"\"\"\n",
    "        #Make sure X and Y have same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"X and Y must have same number of rows!\")\n",
    "            \n",
    "        N = X.shape[0]\n",
    "        K = X.shape[1]\n",
    "        \n",
    "        #Initialize vector of labels\n",
    "        self.labels = np.unique(Y)\n",
    "        \n",
    "        #Initialize probability of each label (called self.prior_probs)\n",
    "        self.num_labels = len(self.labels)\n",
    "        self.prior_counts = np.empty(self.num_labels)\n",
    "        for i in xrange(self.num_labels): \n",
    "            self.prior_counts[i] = len(np.where(Y==self.labels[i]))\n",
    "        self.prior_probs = self.prior_counts/N\n",
    "        \n",
    "        #Create dict of feature probs for each category\n",
    "        self.feature_probs = {}\n",
    "        for label in self.labels:\n",
    "            self.feature_probs[label] = np.ones(K)\n",
    "            label_mask = np.where(Y==label)\n",
    "            self.feature_probs[label] += np.sum(X[label_mask], axis=0)\n",
    "            self.feature_probs[label] /= np.sum(self.feature_probs[label])\n",
    "        print \"Naive Bayes Model has been fit!\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.prediction_probs = np.empty((X.shape[0],self.num_labels))\n",
    "        for i in xrange(self.num_labels):\n",
    "            self.prediction_probs[:,i] = np.log(self.prior_probs[i])+(X.dot(np.log(self.feature_probs[i])))\n",
    "            \n",
    "        return np.argmax(self.prediction_probs, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4:\n",
    "\n",
    "**Test our classifier and benchmark against sklearn implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.loadtxt(\"SpamLabels.txt\")\n",
    "features = np.loadtxt(\"SpamFeatures.txt\")\n",
    "\n",
    "n = len(labels)\n",
    "test_size= 500\n",
    "test_mask = np.random.choice(n, size=test_size, replace=False)\n",
    "train_mask = np.ones(n, dtype=bool)\n",
    "train_mask[test_mask] = 0\n",
    "\n",
    "test_labels = labels[test_mask]\n",
    "test_features = features[test_mask]\n",
    "\n",
    "train_labels = labels[train_mask]\n",
    "train_features = features[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've been initialized!\n",
      "Naive Bayes Model has been fit!\n",
      "Classification rate:  0.995746326373\n"
     ]
    }
   ],
   "source": [
    "spam_classifier = naiveBayes()\n",
    "spam_classifier.fit(train_features, train_labels)\n",
    "test_prediction = spam_classifier.predict(test_features)\n",
    "print \"Classification rate: \", (n-np.sum(np.abs(test_prediction-test_labels)))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate:  0.996133023975\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_features, train_labels)\n",
    "test_prediction = mnb.predict(test_features)\n",
    "print \"Classification rate: \", (n-np.sum(np.abs(test_prediction-test_labels)))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
